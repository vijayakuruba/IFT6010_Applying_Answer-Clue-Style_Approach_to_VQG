{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayakuruba/IFT6010_Applying_Answer-Clue-Style_Approach_to_VQG/blob/main/ACS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3nCdPGgCnVI",
        "outputId": "0762114c-19a8-4148-e52c-18ebb2561ee3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLR2ooxc24Fg",
        "outputId": "37589869-db1b-4fa4-8ab1-302116be719f"
      },
      "source": [
        "%cd /content/drive/My Drive/ACS-VQG\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1gt_GKXoK2_DXdGqoB9OStgaNQSR-jq80/ACS-VQG\n",
            " common\t\t\t\t      get_scores.sh\n",
            " config.py\t\t\t      GPT2_QG\n",
            " Copy_of_get_scores.sh\t\t      merge_vqa.py\n",
            " DA_main_O.py\t\t\t      metric\n",
            " DA_main.py\t\t\t      __pycache__\n",
            " data_augmentor\t\t\t      QG_augment_main.py\n",
            " data_loader\t\t\t      QG_gpt2_generate.py\n",
            " dataq\t\t\t\t      QG_gpt2_train.py\n",
            " experiments_1_QG_train_gpt2.sh       QG_main.py\n",
            " experiments_2_DA_file2sents.sh      'requirements[conflict].txt'\n",
            " experiments_3_DA_sents2augsents.sh   requirements.txt\n",
            " experiments_3_repeat_da_de.sh\t      run_mergevqa.sh\n",
            " experiments_4_QG_generate_gpt2.sh    sampler.py\n",
            " experiments_7_ET.sh\t\t      util\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu0E7BlM5eBj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "193e5915-042f-4eb9-d315-48586ebd80ab"
      },
      "source": [
        "#Install requirements\n",
        "! pip install -r requirements.txt\n",
        "! pip install tensorflow-gpu==1.14.0\n",
        "! pip install torch==1.5.1\n",
        "! pip install sentence-transformers==0.2.4.1\n",
        "! python -m spacy download en_core_web_md\n",
        "! python -m spacy download en\n",
        "import benepar\n",
        "benepar.download('benepar_en2')\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyahocorasick==1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz\n",
            "Collecting benepar==0.1.2\n",
            "  Using cached https://files.pythonhosted.org/packages/a0/7b/6cd9c60e1613a5ad388b4f883fa2aeaddcd8a7ad0a8d5ed87e0d23f159d8/benepar-0.1.2.tar.gz\n",
            "Collecting ftfy==5.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting gensim==3.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/22/18d108180fb6d9408a7c7d3c47e1a7c7a4e0d348420be27faa9a22f57117/gensim-3.7.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 75.4MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 60.5MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/f7/7fd96f43d84a22d068fc999f2ae27f677be4c9501441f5b7870b75842fa4/pandas-0.24.1-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 1.4MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/7f/b535ec711cbcc3246abea4385d17e1b325d4c3404dd86f15fc4f3dba1dbb/scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 122kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/04/7a5015e3087c80037776b75e1a85517dc07f7203f234432a79c132a67dc3/sentencepiece-0.1.82-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 44.6MB/s \n",
            "\u001b[?25hCollecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting spacy==2.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/29/ede5977ea144bb5758407542eb363ebfb11bbb459d26dea5dd0545563854/spacy-2.1.3-cp37-cp37m-manylinux1_x86_64.whl (27.7MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7MB 1.3MB/s \n",
            "\u001b[?25hCollecting textstat==0.5.6\n",
            "  Downloading https://files.pythonhosted.org/packages/66/73/97bb64c89d6f2b24be6ad76007823e19b4c32ed4d484420b3ec6892ac440/textstat-0.5.6-py3-none-any.whl\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 22kB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting transformers==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/99/ca0e4c35ccde7d290de3c9c236d5629d1879b04927e5ace9bd6d9183e236/transformers-2.0.0-py3-none-any.whl (290kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 53.1MB/s \n",
            "\u001b[?25hCollecting visdom==0.1.8.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (0.0)\n",
            "Collecting tensorboardX==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 57.7MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7b/1da69e5fdcb70e8f40ff3955516550207d5f5c81b428a5056510e72c60c5/pytorch_ignite-0.2.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.7MB/s \n",
            "\u001b[?25hCollecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 59.1MB/s \n",
            "\u001b[?25hCollecting torchviz==0.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz==0.10.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.10.1)\n",
            "Collecting allennlp==0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c8/10342a6068a8d156a5947e03c95525d559e71ad62de0f2585ab922e14533/allennlp-0.8.3-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 47.5MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 48kB/s \n",
            "\u001b[?25hCollecting ujson==1.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 48.2MB/s \n",
            "\u001b[?25hCollecting jsondiff==1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/5f/13e28a2f9abeda2ffb3f44f2f809b01b52bc02cdb63816e05b8c9cbbdfc5/jsondiff-1.1.1.tar.gz\n",
            "Collecting jsonnet==0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 44.7MB/s \n",
            "\u001b[?25hCollecting jsonpickle==1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema==2.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.6.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from benepar==0.1.2->-r requirements.txt (line 2)) (0.29.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from benepar==0.1.2->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==5.5.1->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.7.1->-r requirements.txt (line 4)) (5.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.1->-r requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.1->-r requirements.txt (line 6)) (2018.9)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/5f/47b7b29ad202b2210020e2f33bfb06d1db2abe0e709c2a84736e8a9d1bd5/blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.4MB/s \n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/2b/3ecd5d90d2d6fd39fbc520de7d80db5d74defdc2d7c2e15531d9cc3498c7/preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.0MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->-r requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->-r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->-r requirements.txt (line 10)) (0.8.2)\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/42/d7ea7539af3852fd8c1f0b3adf4a100fb3d72b40b69cef1a764ff979a743/thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->-r requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->-r requirements.txt (line 10)) (2.0.5)\n",
            "Collecting repoze.lru\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/30/6cc0c95f0b59ad4b3b9163bff7cdcf793cc96fac64cf398ff26271f5cf5e/repoze.lru-0.7-py3-none-any.whl\n",
            "Collecting pyphen\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/5a/5bc036e01389bc6a6667a932bac3e388de6e7fa5777a6ff50e652f60ec79/Pyphen-0.10.0-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from transformers==2.0.0->-r requirements.txt (line 14)) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/e5/96f7156e6ebf7ab992471479c3c55f0be2f31360fcdcac21aa6f782c036a/boto3-1.17.57-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 64.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.8.8->-r requirements.txt (line 15)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.8.8->-r requirements.txt (line 15)) (22.0.3)\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.8.8->-r requirements.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 16)) (0.22.2.post1)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->-r requirements.txt (line 17)) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (2.10.0)\n",
            "Collecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/43/0e/2f50064e327f41a1eb811df089f813036e19a64b95e33f8e9e0b96c2447e/flaky-3.7.0-py2.py3-none-any.whl\n",
            "Collecting msgpack<0.6.0,>=0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/b6/9affbea179c3c03a0eb53515d9ce404809a122f76bee8fc8c6ec9497f51f/msgpack-0.5.6.tar.gz (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 62.1MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/ba/03b4c978708510c2ab52a75804530edfd96647f3de44abe1cf25d16150ad/responses-0.13.2-py2.py3-none-any.whl\n",
            "Collecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (0.4.1)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/37/f8/b0e12ec2ef211b53803732b3ab49d8d2b7e439ae10132c4bfd0c11a74305/overrides-4.1.2-py3-none-any.whl\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 54.4MB/s \n",
            "\u001b[?25hCollecting moto>=1.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/8a/38157829def6599ac6cb309715f20fc8ab78a65ed7a01457b7f53a016977/moto-2.0.5-py2.py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 57.9MB/s \n",
            "\u001b[?25hCollecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (3.6.4)\n",
            "Collecting conllu==0.11\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (0.5.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (3.2.2)\n",
            "Collecting gevent>=1.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 50.3MB/s \n",
            "\u001b[?25hCollecting awscli>=1.11.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/3f/1d723cbc0aa2105ef11f8b8326e259c6d7c19586c4251d4b86be7018efea/awscli-1.19.57-py2.py3-none-any.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 59.8MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.8.3->-r requirements.txt (line 23)) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (0.36.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (0.2.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (1.32.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->-r requirements.txt (line 24)) (1.12.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 10)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 10)) (3.0.4)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.57\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/52/aa266c9594e279799ded419caac56365796ce686b97762b9c8620b2ba988/botocore-1.20.57-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.0.0->-r requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.0.0->-r requirements.txt (line 14)) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->-r requirements.txt (line 17)) (56.0.0)\n",
            "Collecting typing-utils>=0.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/d6/ed54e008ae5aa828b77089aa371e25cb1313271abebd18d20e650fe903b8/typing_utils-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.7/dist-packages (from moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (1.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (8.7.0)\n",
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe<2.0 in /usr/local/lib/python3.7/dist-packages (from moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (1.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (2.11.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (3.4.1)\n",
            "Collecting cryptography>=3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.3->-r requirements.txt (line 23)) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.3->-r requirements.txt (line 23)) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.3->-r requirements.txt (line 23)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.8.3->-r requirements.txt (line 23)) (20.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.8.3->-r requirements.txt (line 23)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.8.3->-r requirements.txt (line 23)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.8.3->-r requirements.txt (line 23)) (0.10.0)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.8.3->-r requirements.txt (line 23)) (1.0.0)\n",
            "Collecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli>=1.11.91->allennlp==0.8.3->-r requirements.txt (line 23)) (3.13)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2; python_version > \"2.7\" in /usr/local/lib/python3.7/dist-packages (from awscli>=1.11.91->allennlp==0.8.3->-r requirements.txt (line 23)) (4.7.2)\n",
            "Collecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (1.8.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.8.3->-r requirements.txt (line 23)) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 24)) (3.3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3.1->moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (1.14.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2; python_version > \"2.7\"->awscli>=1.11.91->allennlp==0.8.3->-r requirements.txt (line 23)) (0.4.8)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (20.9)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (1.2.4)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (2.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (1.2.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 24)) (3.10.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3.1->moto>=1.3.4->allennlp==0.8.3->-r requirements.txt (line 23)) (2.20)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r requirements.txt (line 23)) (1.1.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->-r requirements.txt (line 24)) (3.7.4.3)\n",
            "Building wheels for collected packages: pyahocorasick, benepar, nltk, visdom, torchviz, ujson, jsondiff, jsonnet, torchfile, msgpack, parsimonious, word2number\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp37-cp37m-linux_x86_64.whl size=82549 sha256=c196c21969ede4cbaf4f5403fadb7a5d2a74fe046a8b7964405e1fa6ac5c7509\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.1.2-cp37-cp37m-linux_x86_64.whl size=104384 sha256=ce6e015bcb40ad3b562dd84f7e34e47464d4f3df0f717355802df6c93dd82bb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/f5/06/d88543b19a9b326007d7538298a139e994b1d2eecb003bf5af\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.4-cp37-none-any.whl size=1450220 sha256=c6c37bc7676fb2757cd962e97f4aa4a57f0ad4dacfa46c87990d7fed52afed20\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/c8/31/48ace4468e236e0e8435f30d33e43df48594e4d53e367cf061\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.8-cp37-none-any.whl size=1350604 sha256=76ae3a7f8add6876a3100c495c94c38b221a7ce4d2557d8210e6cafabdf08146\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/87/ce/a5023722374ca73b57fc8d4284ba6f973c01219b3c385a07e0\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp37-none-any.whl size=3520 sha256=5d36ec1e3af26753009a9bc92d4abe0bddad51a0feb1fa03c27ddf95ca2bea72\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "  Building wheel for ujson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ujson: filename=ujson-1.35-cp37-cp37m-linux_x86_64.whl size=68389 sha256=e0367db65274562ab1fae02a2338ce9d62df283a99825a02a373c0b4ca5ed2ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsondiff: filename=jsondiff-1.1.1-cp37-none-any.whl size=6471 sha256=1e111f33b3726069dfc6fdb7cfa4e8986c7a1d2326e9ebdb822462b2d6f7f75e\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/08/07/69d839606fb7fdc778fa86476abc0a864693d45969a0c1936c\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.12.1-cp37-cp37m-linux_x86_64.whl size=3291940 sha256=502a8117c807afc9784ba10c112afd217dd96e66cfa57e83922f4fba3254a5b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=85fa56652fd9b1357c86cf0f14e00bdb82b01519027d21583095d03c58ccb994\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-0.5.6-cp37-cp37m-linux_x86_64.whl size=298816 sha256=6264ddeaacede8c41905d1e979c6ef0706ff9aa5cff942fcd4e460c3476e56e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/02/4c/525b56fce78c415eb8066f6554f9de02792df26b8f882f6d65\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp37-none-any.whl size=42711 sha256=41aedea635447fceb87c4e94e29fadd5d2078a3a2aabc594376e50886c544777\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp37-none-any.whl size=5589 sha256=f49d9e0d5337fa2e28fc304b670db4890eb25f2bc1f8da84cfdd83ccbe7d31ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "Successfully built pyahocorasick benepar nltk visdom torchviz ujson jsondiff jsonnet torchfile msgpack parsimonious word2number\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.57 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: responses 0.13.2 has requirement urllib3>=1.25.10, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyahocorasick, six, nltk, benepar, ftfy, scipy, gensim, pandas, sentencepiece, blis, preshed, plac, tqdm, thinc, spacy, repoze.lru, pyphen, textstat, torch, jmespath, botocore, s3transfer, boto3, sacremoses, transformers, torchfile, websocket-client, visdom, tensorboardX, pytorch-ignite, pytorch-pretrained-bert, pytorch-transformers, torchviz, flaky, msgpack, responses, parsimonious, word2number, typing-utils, overrides, jsonnet, unidecode, xmltodict, cryptography, moto, flask-cors, conllu, zope.interface, zope.event, gevent, colorama, docutils, awscli, numpydoc, allennlp, tensorboard, tensorflow-estimator, keras-applications, tensorflow, ujson, jsondiff, jsonpickle\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: preshed 3.0.5\n",
            "    Uninstalling preshed-3.0.5:\n",
            "      Successfully uninstalled preshed-3.0.5\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: msgpack 1.0.2\n",
            "    Uninstalling msgpack-1.0.2:\n",
            "      Successfully uninstalled msgpack-1.0.2\n",
            "  Found existing installation: docutils 0.17\n",
            "    Uninstalling docutils-0.17:\n",
            "      Successfully uninstalled docutils-0.17\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed allennlp-0.8.3 awscli-1.19.57 benepar-0.1.2 blis-0.2.4 boto3-1.17.57 botocore-1.20.57 colorama-0.4.3 conllu-0.11 cryptography-3.4.7 docutils-0.15.2 flaky-3.7.0 flask-cors-3.0.10 ftfy-5.5.1 gensim-3.7.1 gevent-21.1.2 jmespath-0.10.0 jsondiff-1.1.1 jsonnet-0.12.1 jsonpickle-1.1 keras-applications-1.0.8 moto-2.0.5 msgpack-0.5.6 nltk-3.4.4 numpydoc-1.1.0 overrides-4.1.2 pandas-0.24.1 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pyahocorasick-1.4.0 pyphen-0.10.0 pytorch-ignite-0.2.0 pytorch-pretrained-bert-0.6.1 pytorch-transformers-1.1.0 repoze.lru-0.7 responses-0.13.2 s3transfer-0.4.2 sacremoses-0.0.45 scipy-1.3.1 sentencepiece-0.1.82 six-1.12.0 spacy-2.1.3 tensorboard-1.14.0 tensorboardX-1.8 tensorflow-1.14.0 tensorflow-estimator-1.14.0 textstat-0.5.6 thinc-7.0.8 torch-1.2.0 torchfile-0.1.0 torchviz-0.0.1 tqdm-4.31.1 transformers-2.0.0 typing-utils-0.0.3 ujson-1.35 unidecode-1.2.0 visdom-0.1.8.8 websocket-client-0.58.0 word2number-1.1 xmltodict-0.12.0 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (56.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Collecting torch==1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/cf/007b6de316c9f3d4cb315a60c308342cc299e464167f5ebc369e93b5e23a/torch-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.2.0\n",
            "    Uninstalling torch-1.2.0:\n",
            "      Successfully uninstalled torch-1.2.0\n",
            "Successfully installed torch-1.5.1\n",
            "Collecting sentence-transformers==0.2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/6e/5c98f5f26698276bacd09077b039fa1a00797ed080a628ee844bd9f281d4/sentence-transformers-0.2.4.1.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hCollecting transformers==2.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (4.31.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.4.1) (3.4.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.2.1->sentence-transformers==0.2.4.1) (1.17.57)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.2.1->sentence-transformers==0.2.4.1) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.2.1->sentence-transformers==0.2.4.1) (0.0.45)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from transformers==2.2.1->sentence-transformers==0.2.4.1) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.2.1->sentence-transformers==0.2.4.1) (0.1.82)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->sentence-transformers==0.2.4.1) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.2.4.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.2.4.1) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.2.1->sentence-transformers==0.2.4.1) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.2.1->sentence-transformers==0.2.4.1) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.57 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.2.1->sentence-transformers==0.2.4.1) (1.20.57)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.2.1->sentence-transformers==0.2.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.2.1->sentence-transformers==0.2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.2.1->sentence-transformers==0.2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.2.1->sentence-transformers==0.2.4.1) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.2.1->sentence-transformers==0.2.4.1) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.57->boto3->transformers==2.2.1->sentence-transformers==0.2.4.1) (2.8.1)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.4.1-cp37-none-any.whl size=61095 sha256=d69e28dd88ae3153c8fd88ce974db951f1ea793d5ec6a8a6e3d8d2e289da142e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/a5/1c/03b7d87e027121fe1e23048007594e73f39a23e833658529c7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: transformers, sentence-transformers\n",
            "  Found existing installation: transformers 2.0.0\n",
            "    Uninstalling transformers-2.0.0:\n",
            "      Successfully uninstalled transformers-2.0.0\n",
            "Successfully installed sentence-transformers-0.2.4.1 transformers-2.2.1\n",
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp37-none-any.whl size=97126236 sha256=40872e9cab67205d665fd6201b2936209e6eddeabf07ffc1a00723be2a719d0a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6le1zqrl/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "Collecting en_core_web_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 7.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-cp37-none-any.whl size=11074434 sha256=382bb1dbec540ab43866fe09f145a6e1333691d53128c2fb7607272f46a4e5ed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jv8gfknw/wheels/39/ea/3b/507f7df78be8631a7a3d7090962194cf55bc1158572c0be77f\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "[nltk_data] Downloading package benepar_en2 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4zn9aSc137u"
      },
      "source": [
        "! python -m spacy download en_core_web_md\n",
        "! python -m spacy download en\n",
        "import benepar\n",
        "benepar.download('benepar_en2')\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlgEb-1APM9j"
      },
      "source": [
        "! chmod 777 ./experiments_1_QG_train_gpt2_vijaya.sh\n",
        "! ./experiments_1_QG_train_gpt2_vijaya.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soCVXh6btarh"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH1bTVq-uRkc"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsIhWmAlWUSg"
      },
      "source": [
        "! chmod 777 ./Get_scores.sh\n",
        "! ./Get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-rnRZ_LO1Zo"
      },
      "source": [
        "cat experiments_2_DA_file2sents.sh | tr -d '\\r' > experiments_2_DA_file2sents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otw9r91zPtSV"
      },
      "source": [
        "! chmod 777 ./experiments_2_DA_file2sents_v.sh\n",
        "! ./experiments_2_DA_file2sents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8by6HZ2zvmtt"
      },
      "source": [
        "! chmod 777 ./experiments_3_DA_sents2augsents_v.sh\n",
        "! ./experiments_3_DA_sents2augsents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjbW7zrlieCU"
      },
      "source": [
        "! chmod 777 ./experiments_4_QG_generate_gpt2_MSCOCO.sh\n",
        "! ./experiments_4_QG_generate_gpt2_MSCOCO.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnzadnv95Mg"
      },
      "source": [
        "! chmod 777 ./experiments_5_uniq_seq2seq_v.sh\n",
        "! ./experiments_5_uniq_seq2seq_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tar6cVR7vxZp"
      },
      "source": [
        "! chmod 777 ./experiments_5_uniq_seq2seq_v.sh\n",
        "! ./experiments_5_uniq_seq2seq_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AKY5imBaLtw"
      },
      "source": [
        "! chmod 777 ./experiments_7_ET_v.sh\n",
        "! ./experiments_7_ET_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2piI_2g4Mlu"
      },
      "source": [
        "! chmod 777 ./experiments_1_ET_train.sh\n",
        "! ./experiments_1_ET_train.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAocOeXQcGZD"
      },
      "source": [
        "cat experiments_7_ET.sh | tr -d '\\r' > experiments_7_ET_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWj1i4J52FY"
      },
      "source": [
        "! chmod 777 ./experiments_7_ET_v.sh\n",
        "! ./experiments_7_ET_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUDvEqezB2IO"
      },
      "source": [
        "! chmod 777 ./Copy_of_experiments_3_DA_sents2augsents.sh\n",
        "! ./Copy_of_experiments_3_DA_sents2augsents.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHPJa_tpNObD"
      },
      "source": [
        "! chmod 777 ./Get_scores.sh\n",
        "! ./Get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqpb4YuFazZK"
      },
      "source": [
        "    import os\n",
        "    from util.file_utils import save, load\n",
        "\n",
        "    CURRENT_PATH = os.getcwd().split(\"/\")\n",
        "    #DATA_PATH = \"/\".join(CURRENT_PATH[:-4]) + \"/Datasets/\"\n",
        "    DATA_PATH = \"./dataq/\" \n",
        "\n",
        "    SAMPLE_PROBS_FILE_PATH = DATA_PATH + \"processed/SQuAD1.1-Zhou/squad_sample_probs.pkl\"\n",
        "    DATA_ACS_INFO_FILE_PATH = DATA_PATH + \"processed/SQuAD1.1-Zhou/squad_ans_clue_style_info.pkl\"\n",
        "    acs = load(DATA_ACS_INFO_FILE_PATH)\n",
        "\n",
        "\n",
        "    SAMPLE_PROBS = load(SAMPLE_PROBS_FILE_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJez_HYazWG"
      },
      "source": [
        "   acs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-UPfbCRTRl9"
      },
      "source": [
        "SAMPLE_PROBS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcMHD_XKV896"
      },
      "source": [
        "! chmod 777 ./experiments_3_DA_sents2augsents_v.sh\n",
        "! ./experiments_3_DA_sents2augsents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIG7-Q_KZAYh"
      },
      "source": [
        "! chmod 777 ./experiments_4_QG_generate_gpt2_MSCOCO.sh\n",
        "! ./experiments_4_QG_generate_gpt2_MSCOCO.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMhwYSkdfwof"
      },
      "source": [
        "! chmod 777 ./experiments_2_DA_file2sents_v.sh\n",
        "! ./experiments_2_DA_file2sents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMZyVGtEgmsJ"
      },
      "source": [
        "! chmod 777 ./experiments_3_DA_sents2augsents_v.sh\n",
        "! ./experiments_3_DA_sents2augsents_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "646Nr6l9jDx0"
      },
      "source": [
        "! chmod 777 ./experiments_4_QG_generate_gpt2_MSCOCO.sh\n",
        "! ./experiments_4_QG_generate_gpt2_MSCOCO.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIzgU4SOpkMh"
      },
      "source": [
        "! chmod 777 ./experiments_5_uniq_seq2seq_v.sh\n",
        "! ./experiments_5_uniq_seq2seq_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyRJ8KcMyOBd"
      },
      "source": [
        "! chmod 777 ./experiments_6_postprocess_seq2seq_v.sh\n",
        "! ./experiments_6_postprocess_seq2seq_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRxj1GSq2sx3"
      },
      "source": [
        "! chmod 777 ./experiments_7_ET_v.sh\n",
        "! ./experiments_7_ET_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxrcFShM9ady"
      },
      "source": [
        "    import os\n",
        "    from util.file_utils import save, load\n",
        "\n",
        "    CURRENT_PATH = os.getcwd().split(\"/\")\n",
        "    #DATA_PATH = \"/\".join(CURRENT_PATH[:-4]) + \"/Datasets/\"\n",
        "    DATA_PATH = \"./dataq/\" \n",
        "\n",
        "    SAMPLE_PROBS_FILE_PATH = DATA_PATH + \"processed/SQuAD2.0/train.sentences.augmented.0_5000.processed.pkl\"\n",
        "    DATA_ACS_INFO_FILE_PATH = DATA_PATH + \"processed/SQuAD1.1-Zhou/squad_ans_clue_style_info.pkl\"\n",
        "    acs = load(SAMPLE_PROBS_FILE_PATH)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSEOIBaVL0tn"
      },
      "source": [
        "print(acs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvO3o4tO-PAE"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./dataq/processed/SQuAD2.0/train.qa.0_5000.txt',error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvjH5Nrx-xfe"
      },
      "source": [
        "! chmod 777 ./experiments_1_QG_train_seq2seq_v.sh\n",
        "! ./experiments_1_QG_train_seq2seq_v.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuqcB2JanmL9"
      },
      "source": [
        "! pip install torch==1.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW-0QdNDZJtE"
      },
      "source": [
        "! chmod 777 ./Get_scores.sh\n",
        "! ./Get_scores.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok3lxHnG8E7I"
      },
      "source": [
        "import json\n",
        "\n",
        "import os\n",
        "\n",
        "CURRENT_PATH = os.getcwd().split(\"/\")\n",
        "    #DATA_PATH = \"/\".join(CURRENT_PATH[:-4]) + \"/Datasets/\"\n",
        "DATA_PATH = \"./dataq/\" \n",
        "json_file = DATA_PATH + \"processed/SQuAD2.0/train.qa.0_5000.qg.generated.gpt2.json\"\n",
        "\n",
        "with open(json_file, 'r') as file:\n",
        "     parsed = json.load(file)\n",
        "\n",
        "print(json.dumps(parsed,sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD9LHDmrAY5B"
      },
      "source": [
        "output_json = json.load(open(json_file ))\n",
        "\n",
        "for majorkey, subdict in output_json.items():\n",
        "    print (majorkey)\n",
        "    for subkey, value in subdict.items():\n",
        "            print (subkey, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQ4UKrj-IvX"
      },
      "source": [
        "for key, value in parsed.items():\n",
        "    result = value[0][1]\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUDzuGai1KEO"
      },
      "source": [
        "! chmod 777 ./Get_scores.sh\n",
        "! ./Get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHJnL-XEs0k-"
      },
      "source": [
        "! chmod 777 ./experiments_3_DA_sents2augsents.sh\n",
        "! ./experiments_3_DA_sents2augsents.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U40Y1Yud7wOX"
      },
      "source": [
        "! python -m pip freeze | grep transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxJMZZEA-6Uj"
      },
      "source": [
        "! pip install sentence-transformers==0.2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPD74bfg6URI"
      },
      "source": [
        "# run mergeVQA\n",
        "! chmod 777 ./run_mergevqa.sh\n",
        "! ./run_mergevqa.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w39lL8NRHTm"
      },
      "source": [
        "#RUN VQA SENTENCES run 3\n",
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZMPBahNTzDz"
      },
      "source": [
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "midcU9qptCjh"
      },
      "source": [
        "# Toning\n",
        "\n",
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG4LDazSRZ-5",
        "outputId": "5f5b5cd7-03ac-44fb-abf8-0ccf1d640d71"
      },
      "source": [
        "#Run Squad 1.1 dev set scores\n",
        "\n",
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Start loading constants ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-04-23 01:56:10.920772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-23 01:56:10.948083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:10.948780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-23 01:56:10.949327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-23 01:56:10.950971: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-23 01:56:10.952278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-23 01:56:10.952936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-23 01:56:10.954563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-23 01:56:10.955822: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-23 01:56:10.955901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-23 01:56:10.956001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:10.956682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:10.957270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-23 01:56:10.957701: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-04-23 01:56:10.962501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2021-04-23 01:56:10.962827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555571164140 executing computations on platform Host. Devices:\n",
            "2021-04-23 01:56:10.962863: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-23 01:56:11.040185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:11.041010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555571163f80 executing computations on platform CUDA. Devices:\n",
            "2021-04-23 01:56:11.041052: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-04-23 01:56:11.041248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:11.041881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-23 01:56:11.042001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-23 01:56:11.042026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-23 01:56:11.042044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-23 01:56:11.042080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-23 01:56:11.042097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-23 01:56:11.042114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-23 01:56:11.042129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-23 01:56:11.042187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:11.042771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:11.043301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-23 01:56:14.017074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-23 01:56:14.017154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-04-23 01:56:14.017165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-04-23 01:56:14.017421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:14.018097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 01:56:14.018651: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-23 01:56:14.018698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14345 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "tcmalloc: large alloc 2635227136 bytes == 0x55563f5da000 @  0x7f496ea07001 0x7f491d6b454f 0x7f491d704b58 0x7f491d708b17 0x7f491d7a7203 0x55556e0500e4 0x55556e04fde0 0x55556e0c46f5 0x55556e0bee0d 0x55556e05177a 0x55556e0c086a 0x55556e0beb0e 0x55556e05177a 0x55556e0c086a 0x55556e0beb0e 0x55556e0be813 0x55556e0bcbbb 0x55556e1657a2 0x55556e05238a 0x55556e0c5343 0x55556e0beb0e 0x55556e05177a 0x55556e0c3e50 0x55556e05169a 0x55556e0bfc9e 0x55556e05169a 0x55556e0bfa45 0x55556e05169a 0x55556e0bfa45 0x55556e05122a 0x55556e052d6d\n",
            "Finished loading constants ...\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Namespace(calc_tg_metrics=True, data_type='squad', debug=False, debug_num=20, device='cuda', filecache='', filename='./dataq/original/SQuAD1.1-Zhou/test.txt', max_length=50, min_length=1, model_name='', model_name_or_path='./dataq/output/QG/gpt2_question_generation', model_type='gpt2', no_sample=False, output_file='./dataq/processed/SQuAD1.1-Zhou/test.squad1.1.qg.generated.gpt2.json', save_freq=2000, seed=42, temperature=0.7, top_k=0, top_p=0.9)\n",
            "Get pretrained model and tokenizer\n",
            "Start get SQuAD raw examples ...\n",
            "100% 8964/8964 [00:00<00:00, 10042.63it/s]\n",
            "Time of get raw examples: 0:00:02.194776\n",
            "Number of raw examples:  8964\n",
            "Start transform raw examples to processed examples...\n",
            "  0% 0/8964 [00:00<?, ?it/s]2021-04-23 01:57:36.187547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "100% 8964/8964 [10:31<00:00, 14.19it/s]\n",
            "num_not_match_error:  992\n",
            "num_spans_len_error:  3\n",
            "Time of get processed examples: 0:10:31.493052\n",
            "Number of processed examples:  8733\n",
            "100% 8733/8733 [00:08<00:00, 984.13it/s] \n",
            "0 / 8733 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "Time of get_positional_dataset_from_file: 0:10:42.568806\n",
            " 24% 2074/8733 [05:53<18:42,  5.93it/s]saved generated questions. 2000\n",
            " 47% 4144/8733 [11:46<15:57,  4.79it/s]saved generated questions. 4000\n",
            " 71% 6236/8733 [17:39<08:12,  5.07it/s]saved generated questions. 6000\n",
            " 95% 8325/8733 [23:32<01:07,  6.03it/s]saved generated questions. 8000\n",
            "100% 8733/8733 [24:43<00:00,  6.66it/s]\n",
            "Time of generate 8384 questions: 0:24:43.562847\n",
            "{'Bleu_1': 0.3285195426622684, 'Bleu_2': 0.20800686162567225, 'Bleu_3': 0.14168314811277474, 'Bleu_4': 0.10070365971444456, 'METEOR': 0.18339343382332585, 'ROUGE_L': 0.33055426774661734, 'CIDEr': 0.9007871624995015}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svJxc5GXZj7u",
        "outputId": "8db2f34b-3614-459b-db25-2a2253afb7b0"
      },
      "source": [
        "#Run2 squad1.1\n",
        "\n",
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Start loading constants ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-04-25 15:11:43.154638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-25 15:11:43.176054: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-25 15:11:43.176122: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (302039eefe45): /proc/driver/nvidia/version does not exist\n",
            "2021-04-25 15:11:43.176600: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-04-25 15:11:43.182011: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1999995000 Hz\n",
            "2021-04-25 15:11:43.182565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56280a244300 executing computations on platform Host. Devices:\n",
            "2021-04-25 15:11:43.182609: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "tcmalloc: large alloc 2635227136 bytes == 0x5628bdfdc000 @  0x7fd9b4912001 0x7fd9635bf54f 0x7fd96360fb58 0x7fd963613b17 0x7fd9636b2203 0x562806d630e4 0x562806d62de0 0x562806dd76f5 0x562806dd1e0d 0x562806d6477a 0x562806dd386a 0x562806dd1b0e 0x562806d6477a 0x562806dd386a 0x562806dd1b0e 0x562806dd1813 0x562806dcfbbb 0x562806e787a2 0x562806d6538a 0x562806dd8343 0x562806dd1b0e 0x562806d6477a 0x562806dd6e50 0x562806d6469a 0x562806dd2c9e 0x562806d6469a 0x562806dd2a45 0x562806d6469a 0x562806dd2a45 0x562806d6422a 0x562806d65d6d\n",
            "Finished loading constants ...\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Namespace(calc_tg_metrics=True, data_type='squad', debug=False, debug_num=20, device='cpu', filecache='', filename='./dataq/original/SQuAD1.1-Zhou/test.txt', max_length=50, min_length=1, model_name='', model_name_or_path='./dataq/output/QG/gpt2_question_generation', model_type='gpt2', no_sample=False, output_file='./dataq/processed/SQuAD1.1-Zhou/test.squad1.1.qg.generated.gpt2.json', save_freq=2000, seed=42, temperature=0.7, top_k=0, top_p=0.9)\n",
            "Get pretrained model and tokenizer\n",
            "Start get SQuAD raw examples ...\n",
            "100% 8964/8964 [00:00<00:00, 8990.06it/s]\n",
            "Time of get raw examples: 0:00:02.904034\n",
            "Number of raw examples:  8964\n",
            "Start transform raw examples to processed examples...\n",
            "  0% 0/8964 [00:00<?, ?it/s]2021-04-25 15:13:40.757866: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "100% 8964/8964 [38:05<00:00,  4.16it/s]\n",
            "num_not_match_error:  992\n",
            "num_spans_len_error:  3\n",
            "Time of get processed examples: 0:38:05.046856\n",
            "Number of processed examples:  8733\n",
            "100% 8733/8733 [00:09<00:00, 902.49it/s]\n",
            "0 / 8733 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "Time of get_positional_dataset_from_file: 0:38:17.632346\n",
            " 24% 2074/8733 [26:47<1:34:05,  1.18it/s]saved generated questions. 2000\n",
            " 47% 4144/8733 [53:49<1:03:51,  1.20it/s]saved generated questions. 4000\n",
            " 71% 6236/8733 [1:20:41<42:19,  1.02s/it]saved generated questions. 6000\n",
            " 95% 8325/8733 [1:48:09<04:49,  1.41it/s]saved generated questions. 8000\n",
            "100% 8733/8733 [1:53:34<00:00,  1.35it/s]\n",
            "Time of generate 8384 questions: 1:53:34.565832\n",
            "{'Bleu_1': 0.41586986563121897, 'Bleu_2': 0.298788972156824, 'Bleu_3': 0.2271689892939419, 'Bleu_4': 0.1779695163773873, 'METEOR': 0.24436252883026488, 'ROUGE_L': 0.4191951164434025, 'CIDEr': 1.6928793417787995}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv_V0ihdlbVH",
        "outputId": "19f03072-cac0-4ecd-b046-1e2b70a3a1f1"
      },
      "source": [
        "# Retrain for new questions types\n",
        "\n",
        "! chmod 777 ./experiments_1_QG_train_gpt2.sh\n",
        "! ./experiments_1_QG_train_gpt2.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02:41:27 : 1) QG_gpt2_train.py \n",
            "********************************************************************************\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Start loading constants ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-04-23 02:41:36.126574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-23 02:41:36.155108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.155781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-23 02:41:36.156182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-23 02:41:36.157399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-23 02:41:36.158625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-23 02:41:36.159047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-23 02:41:36.160475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-23 02:41:36.161529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-23 02:41:36.161620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-23 02:41:36.161743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.162421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.163025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-23 02:41:36.163449: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-04-23 02:41:36.168473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2021-04-23 02:41:36.168798: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651cdc0a140 executing computations on platform Host. Devices:\n",
            "2021-04-23 02:41:36.168838: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-23 02:41:36.250562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.251403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651cdc09f80 executing computations on platform CUDA. Devices:\n",
            "2021-04-23 02:41:36.251446: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-04-23 02:41:36.251678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.252406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-23 02:41:36.252546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-23 02:41:36.252569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-23 02:41:36.252587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-23 02:41:36.252606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-23 02:41:36.252623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-23 02:41:36.252640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-23 02:41:36.252654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-23 02:41:36.252731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.253346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:36.253926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-23 02:41:39.597568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-23 02:41:39.597639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-04-23 02:41:39.597653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-04-23 02:41:39.597902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:39.598520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-23 02:41:39.599090: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-23 02:41:39.599184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14345 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "tcmalloc: large alloc 2635227136 bytes == 0x56529bd18000 @  0x7fa0a1419001 0x7fa050aab54f 0x7fa050afbb58 0x7fa050affb17 0x7fa050b9e203 0x5651c99c20e4 0x5651c99c1de0 0x5651c9a366f5 0x5651c9a30e0d 0x5651c99c377a 0x5651c9a3286a 0x5651c9a30b0e 0x5651c99c377a 0x5651c9a3286a 0x5651c9a30b0e 0x5651c9a30813 0x5651c9a2ebbb 0x5651c9ad77a2 0x5651c99c438a 0x5651c9a37343 0x5651c9a30b0e 0x5651c99c377a 0x5651c9a35e50 0x5651c99c369a 0x5651c9a31c9e 0x5651c99c369a 0x5651c9a31a45 0x5651c99c369a 0x5651c9a31a45 0x5651c99c322a 0x5651c99c4d6d\n",
            "Finished loading constants ...\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "started\n",
            "WARNING:/content/drive/.shortcut-targets-by-id/1gt_GKXoK2_DXdGqoB9OStgaNQSR-jq80/ACS-VQG/GPT2_QG/train.py:Running process -1\n",
            "100% 665/665 [00:00<00:00, 605955.28B/s]\n",
            "100% 1042301/1042301 [00:00<00:00, 2034902.36B/s]\n",
            "100% 456318/456318 [00:00<00:00, 1308120.81B/s]\n",
            "100% 548118077/548118077 [00:27<00:00, 19638156.17B/s]\n",
            "Start get SQuAD raw examples ...\n",
            "100% 86635/86635 [00:07<00:00, 11134.17it/s]\n",
            "Time of get raw examples: 0:00:10.541456\n",
            "Number of raw examples:  86635\n",
            "Start transform raw examples to processed examples...\n",
            "  0% 0/86635 [00:00<?, ?it/s]2021-04-23 02:43:36.029625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 45% 39114/86635 [41:41<51:03, 15.51it/s]  Sentence of length 382 is too long to be parsed\n",
            " 45% 39116/86635 [41:47<12:05:36,  1.09it/s]Sentence of length 382 is too long to be parsed\n",
            "Sentence of length 382 is too long to be parsed\n",
            " 45% 39118/86635 [41:59<31:43:32,  2.40s/it]Sentence of length 382 is too long to be parsed\n",
            " 45% 39119/86635 [42:05<44:23:19,  3.36s/it]Sentence of length 382 is too long to be parsed\n",
            " 56% 48485/86635 [52:41<49:28, 12.85it/s]Sentence of length 432 is too long to be parsed\n",
            " 56% 48488/86635 [52:46<5:31:09,  1.92it/s]Sentence of length 432 is too long to be parsed\n",
            "Sentence of length 432 is too long to be parsed\n",
            " 56% 48490/86635 [52:54<16:19:39,  1.54s/it]Sentence of length 432 is too long to be parsed\n",
            " 56% 48491/86635 [52:58<23:54:06,  2.26s/it]Sentence of length 432 is too long to be parsed\n",
            "100% 86635/86635 [1:35:15<00:00, 15.16it/s]\n",
            "num_not_match_error:  10414\n",
            "num_spans_len_error:  41\n",
            "Time of get processed examples: 1:35:15.745914\n",
            "Number of processed examples:  84379\n",
            "100% 84379/84379 [01:21<00:00, 1040.16it/s]\n",
            "0 / 84379 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "Start get SQuAD raw examples ...\n",
            "100% 8965/8965 [00:00<00:00, 9799.21it/s]\n",
            "Time of get raw examples: 0:00:01.061040\n",
            "Number of raw examples:  8965\n",
            "Start transform raw examples to processed examples...\n",
            "100% 8965/8965 [10:24<00:00, 17.38it/s]\n",
            "num_not_match_error:  1018\n",
            "num_spans_len_error:  2\n",
            "Time of get processed examples: 0:10:24.981753\n",
            "Number of processed examples:  8708\n",
            "100% 8708/8708 [00:08<00:00, 1001.74it/s]\n",
            "0 / 8708 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "hahhaha\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f9e62724850>\n",
            "Validation: {'average_nll': 80.551515851702,\n",
            " 'average_ppl': 9.617868686813524e+34,\n",
            " 'nll': 80.551515851702}\n",
            "Epoch [1/4]:   0% 7/21095 [00:01<1:12:45,  4.83it/s, loss=7.68e+00]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "Validation: {'average_nll': 1.8388167549066714,\n",
            " 'average_ppl': 6.289092319080214,\n",
            " 'nll': 1.8388167549066714}\n",
            "Epoch [1/4]: 100% 21095/21095 [1:21:28<00:00,  4.68it/s, loss=2.23e-01]\n",
            "Validation: {'average_nll': 1.7950802819959932,\n",
            " 'average_ppl': 6.019957996651622,\n",
            " 'nll': 1.7950802819959932}\n",
            "Epoch [2/4]: 100% 21095/21095 [1:21:19<00:00,  4.71it/s, loss=2.01e-01]\n",
            "Validation: {'average_nll': 1.796749580738793,\n",
            " 'average_ppl': 6.030015497118098,\n",
            " 'nll': 1.796749580738793}\n",
            "Epoch [3/4]: 100% 21095/21095 [1:21:18<00:00,  4.67it/s, loss=1.86e-01]\n",
            "Validation: {'average_nll': 1.8049395461393487,\n",
            " 'average_ppl': 6.079603901883544,\n",
            " 'nll': 1.8049395461393487}\n",
            "Epoch [4/4]: 100% 21095/21095 [1:21:15<00:00,  4.70it/s, loss=1.61e-01]\n",
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: [Errno 2] No such file or directory.\n",
            "Traceback (most recent call last):\n",
            "  File \"QG_gpt2_train.py\", line 5, in <module>\n",
            "    train()\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1gt_GKXoK2_DXdGqoB9OStgaNQSR-jq80/ACS-VQG/GPT2_QG/train.py\", line 414, in train\n",
            "    trainer.run(train_loader, max_epochs=args.n_epochs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 359, in run\n",
            "    self._handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 324, in _handle_exception\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 350, in run\n",
            "    self._fire_event(Events.EPOCH_COMPLETED)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 259, in _fire_event\n",
            "    func(self, *(event_args + args), **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/handlers/checkpoint.py\", line 172, in __call__\n",
            "    self._save(obj=obj, path=path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/handlers/checkpoint.py\", line 128, in _save\n",
            "    tmp = tempfile.NamedTemporaryFile(delete=False, dir=self._dirname)\n",
            "  File \"/usr/lib/python3.7/tempfile.py\", line 686, in NamedTemporaryFile\n",
            "    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n",
            "  File \"/usr/lib/python3.7/tempfile.py\", line 408, in _mkstemp_inner\n",
            "    return (fd, _os.path.abspath(file))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy0fu1pdungQ",
        "outputId": "0e321ff6-5c1f-420e-f816-caf3ed31e35e"
      },
      "source": [
        "# Retrain for new questions types\n",
        "\n",
        "! chmod 777 ./experiments_1_QG_train_gpt2.sh\n",
        "! ./experiments_1_QG_train_gpt2.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:41:21 : 1) QG_gpt2_train.py \n",
            "********************************************************************************\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Start loading constants ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-04-25 03:41:30.374932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-25 03:41:30.392997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.393578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-25 03:41:30.393944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-25 03:41:30.395162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-25 03:41:30.396274: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-25 03:41:30.396629: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-25 03:41:30.398027: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-25 03:41:30.398994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-25 03:41:30.399077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-25 03:41:30.399157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.399723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.400258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-25 03:41:30.400571: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-25 03:41:30.404760: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-04-25 03:41:30.405036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fb429e140 executing computations on platform Host. Devices:\n",
            "2021-04-25 03:41:30.405072: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-25 03:41:30.478468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.479219: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fb429df80 executing computations on platform CUDA. Devices:\n",
            "2021-04-25 03:41:30.479253: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-04-25 03:41:30.479437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.480001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-25 03:41:30.480120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-25 03:41:30.480147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-25 03:41:30.480164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-25 03:41:30.480181: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-25 03:41:30.480198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-25 03:41:30.480241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-25 03:41:30.480255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-25 03:41:30.480309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.480859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:30.481507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-25 03:41:32.612114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-25 03:41:32.612178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-04-25 03:41:32.612192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-04-25 03:41:32.612415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:32.613088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-25 03:41:32.613653: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-25 03:41:32.613701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14810 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "tcmalloc: large alloc 2635227136 bytes == 0x557068654000 @  0x7f0838112001 0x7f07e77a454f 0x7f07e77f4b58 0x7f07e77f8b17 0x7f07e7897203 0x556faffe00e4 0x556faffdfde0 0x556fb00546f5 0x556fb004ee0d 0x556faffe177a 0x556fb005086a 0x556fb004eb0e 0x556faffe177a 0x556fb005086a 0x556fb004eb0e 0x556fb004e813 0x556fb004cbbb 0x556fb00f57a2 0x556faffe238a 0x556fb0055343 0x556fb004eb0e 0x556faffe177a 0x556fb0053e50 0x556faffe169a 0x556fb004fc9e 0x556faffe169a 0x556fb004fa45 0x556faffe169a 0x556fb004fa45 0x556faffe122a 0x556faffe2d6d\n",
            "Finished loading constants ...\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "started\n",
            "WARNING:/content/drive/My Drive/Try/RetrainGPT2/GPT2_QG/train.py:Running process -1\n",
            "Start get SQuAD raw examples ...\n",
            "100% 86635/86635 [00:06<00:00, 12437.19it/s]\n",
            "Time of get raw examples: 0:00:10.029691\n",
            "Number of raw examples:  86635\n",
            "Start transform raw examples to processed examples...\n",
            "  0% 0/86635 [00:00<?, ?it/s]2021-04-25 03:42:53.020966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 45% 39114/86635 [36:49<53:34, 14.78it/s]  Sentence of length 382 is too long to be parsed\n",
            "Sentence of length 382 is too long to be parsed\n",
            " 45% 39117/86635 [36:59<14:14:04,  1.08s/it]Sentence of length 382 is too long to be parsed\n",
            " 45% 39118/86635 [37:05<32:02:05,  2.43s/it]Sentence of length 382 is too long to be parsed\n",
            " 45% 39119/86635 [37:10<42:26:30,  3.22s/it]Sentence of length 382 is too long to be parsed\n",
            " 56% 48485/86635 [46:37<40:19, 15.77it/s]Sentence of length 432 is too long to be parsed\n",
            " 56% 48488/86635 [46:41<4:21:35,  2.43it/s]Sentence of length 432 is too long to be parsed\n",
            "Sentence of length 432 is too long to be parsed\n",
            " 56% 48490/86635 [46:48<15:15:03,  1.44s/it]Sentence of length 432 is too long to be parsed\n",
            " 56% 48491/86635 [46:52<22:01:44,  2.08s/it]Sentence of length 432 is too long to be parsed\n",
            "100% 86635/86635 [1:23:22<00:00, 17.32it/s]\n",
            "num_not_match_error:  10415\n",
            "num_spans_len_error:  41\n",
            "Time of get processed examples: 1:23:22.107567\n",
            "Number of processed examples:  84379\n",
            "100% 84379/84379 [01:08<00:00, 1228.17it/s]\n",
            "0 / 84379 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "Start get SQuAD raw examples ...\n",
            "100% 8965/8965 [00:01<00:00, 5648.41it/s]\n",
            "Time of get raw examples: 0:00:04.335189\n",
            "Number of raw examples:  8965\n",
            "Start transform raw examples to processed examples...\n",
            "100% 8965/8965 [09:04<00:00, 16.45it/s]\n",
            "num_not_match_error:  1018\n",
            "num_spans_len_error:  2\n",
            "Time of get processed examples: 0:09:04.841854\n",
            "Number of processed examples:  8708\n",
            "100% 8708/8708 [00:07<00:00, 1240.71it/s]\n",
            "0 / 8708 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f06298a04d0>\n",
            "Validation: {'average_nll': 1.796751624436131,\n",
            " 'average_ppl': 6.030027820657311,\n",
            " 'nll': 1.796751624436131}\n",
            "Epoch:   0% 7/21095 [00:02<2:16:30,  2.57it/s, loss=2.01e-01]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "Validation: {'average_nll': 1.7978427962365366,\n",
            " 'average_ppl': 6.036611208121037,\n",
            " 'nll': 1.7978427962365366}\n",
            "Epoch: 100% 21095/21095 [2:32:12<00:00,  2.60it/s, loss=1.70e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMLDUtkSUgZY",
        "outputId": "d88fc0c8-6ab1-4c78-e114-da024e957887"
      },
      "source": [
        "# generate VQA on run2\n",
        "! chmod 777 ./get_scores.sh\n",
        "! ./get_scores.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Start loading constants ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-04-26 17:19:52.363964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-26 17:19:52.391790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.392525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-26 17:19:52.392955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-26 17:19:52.394647: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-26 17:19:52.396249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-26 17:19:52.396714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-26 17:19:52.398416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-26 17:19:52.399757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-26 17:19:52.399873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-26 17:19:52.399988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.400685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.401332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-26 17:19:52.401759: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-04-26 17:19:52.408691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
            "2021-04-26 17:19:52.409212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f94b7c140 executing computations on platform Host. Devices:\n",
            "2021-04-26 17:19:52.409251: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-26 17:19:52.486794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.487720: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f94b7bf80 executing computations on platform CUDA. Devices:\n",
            "2021-04-26 17:19:52.487766: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-04-26 17:19:52.487983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.488578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-26 17:19:52.488714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-26 17:19:52.488740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-26 17:19:52.488758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-26 17:19:52.488776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-26 17:19:52.488795: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-26 17:19:52.488812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-26 17:19:52.488827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-26 17:19:52.488895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.489532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:52.490121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-26 17:19:55.825534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-26 17:19:55.825613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-04-26 17:19:55.825626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-04-26 17:19:55.825894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:55.826571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-26 17:19:55.827193: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-26 17:19:55.827268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14345 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "tcmalloc: large alloc 2635227136 bytes == 0x563062c76000 @  0x7fcb7d496001 0x7fcb2c14354f 0x7fcb2c193b58 0x7fcb2c197b17 0x7fcb2c236203 0x562f90e690e4 0x562f90e68de0 0x562f90edd6f5 0x562f90ed7e0d 0x562f90e6a77a 0x562f90ed986a 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed986a 0x562f90ed7b0e 0x562f90ed7813 0x562f90ed5bbb 0x562f90f7e7a2 0x562f90e6b38a 0x562f90ede343 0x562f90ed7b0e 0x562f90e6a77a 0x562f90edce50 0x562f90e6a69a 0x562f90ed8c9e 0x562f90e6a69a 0x562f90ed8a45 0x562f90e6a69a 0x562f90ed8a45 0x562f90e6a22a 0x562f90e6bd6d\n",
            "Finished loading constants ...\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Namespace(calc_tg_metrics=True, data_type='vqa', debug=False, debug_num=20, device='cuda', filecache='', filename='./dataq/processed/VQA/vqa_test.json', max_length=50, min_length=1, model_name='', model_name_or_path='./dataq/output/QG/gpt2_question_generation', model_type='gpt2', no_sample=False, output_file='./dataq/processed/VQA/test.VQA.qg.generated.gpt2_Run2.json', save_freq=2000, seed=42, temperature=0.7, top_k=0, top_p=0.9)\n",
            "Get pretrained model and tokenizer\n",
            "/content/drive/.shortcut-targets-by-id/1gt_GKXoK2_DXdGqoB9OStgaNQSR-jq80/ACS-VQG/dataq/processed/SQuAD1.1-Zhou/squad_sample_probs.pkl loaded.\n",
            "\n",
            "tcmalloc: large alloc 2147491840 bytes == 0x56312e544000 @  0x7fcb7d4941e7 0x562f90e9af48 0x562f90e659c7 0x562f90f473fe 0x562f90e68ee9 0x562f90f5a99d 0x562f90edcfe9 0x562f90e6a69a 0x562f90ed8a45 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed8a45 0x562f90e6a69a 0x562f90ed8a45 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed8a45 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed8a45 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed986a 0x562f90ed7b0e 0x562f90e6a77a 0x562f90ed986a 0x562f90e6a69a 0x562f90ed8a45 0x562f90ed7b0e 0x562f90ed7813 0x562f90fa1592\n",
            "Start get VQA raw examples ...\n",
            "  0% 0/10000 [00:00<?, ?it/s]2021-04-26 17:21:07.512723: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 47% 4747/10000 [13:10<19:42,  4.44it/s][DEBUG] Not found! 0.8 ---> 0.7200000000000001\n",
            "[DEBUG] Not found! 0.7200000000000001 ---> 0.6480000000000001\n",
            "[DEBUG] Not found! 0.6480000000000001 ---> 0.5832000000000002\n",
            "[DEBUG] Not found! 0.5832000000000002 ---> 0.5248800000000001\n",
            "[DEBUG] Not found! 0.5248800000000001 ---> 0.47239200000000015\n",
            "[DEBUG] Not found! 0.47239200000000015 ---> 0.42515280000000016\n",
            "[DEBUG] Not found! 0.42515280000000016 ---> 0.3826375200000002\n",
            "[DEBUG] Not found! 0.8 ---> 0.7200000000000001\n",
            "[DEBUG] Not found! 0.7200000000000001 ---> 0.6480000000000001\n",
            "[DEBUG] Not found! 0.6480000000000001 ---> 0.5832000000000002\n",
            "[DEBUG] Not found! 0.5832000000000002 ---> 0.5248800000000001\n",
            "[DEBUG] Not found! 0.5248800000000001 ---> 0.47239200000000015\n",
            "[DEBUG] Not found! 0.47239200000000015 ---> 0.42515280000000016\n",
            "[DEBUG] Not found! 0.42515280000000016 ---> 0.3826375200000002\n",
            " 48% 4751/10000 [13:10<17:04,  5.13it/s][DEBUG] Not found! 0.8 ---> 0.7200000000000001\n",
            "[DEBUG] Not found! 0.7200000000000001 ---> 0.6480000000000001\n",
            "[DEBUG] Not found! 0.6480000000000001 ---> 0.5832000000000002\n",
            "[DEBUG] Not found! 0.5832000000000002 ---> 0.5248800000000001\n",
            "[DEBUG] Not found! 0.5248800000000001 ---> 0.47239200000000015\n",
            "[DEBUG] Not found! 0.47239200000000015 ---> 0.42515280000000016\n",
            "[DEBUG] Not found! 0.42515280000000016 ---> 0.3826375200000002\n",
            " 48% 4754/10000 [13:11<16:16,  5.37it/s][DEBUG] Not found! 0.8 ---> 0.7200000000000001\n",
            "[DEBUG] Not found! 0.7200000000000001 ---> 0.6480000000000001\n",
            "[DEBUG] Not found! 0.6480000000000001 ---> 0.5832000000000002\n",
            "[DEBUG] Not found! 0.5832000000000002 ---> 0.5248800000000001\n",
            "[DEBUG] Not found! 0.5248800000000001 ---> 0.47239200000000015\n",
            "[DEBUG] Not found! 0.47239200000000015 ---> 0.42515280000000016\n",
            "[DEBUG] Not found! 0.42515280000000016 ---> 0.3826375200000002\n",
            "100% 10000/10000 [27:01<00:00,  5.72it/s]\n",
            "Time of get raw examples: 0:27:01.534036\n",
            "Number of raw examples:  10000\n",
            "Start transform raw examples to processed examples...\n",
            "100% 10000/10000 [05:22<00:00, 30.98it/s]\n",
            "num_not_match_error:  0\n",
            "num_spans_len_error:  0\n",
            "Time of get processed examples: 0:05:22.766513\n",
            "Number of processed examples:  10000\n",
            "100% 10000/10000 [00:05<00:00, 1758.18it/s]\n",
            "0 / 10000 sequences truncated due to positional embedding restriction\n",
            "Dataset cached at %s \n",
            "Time of get_positional_dataset_from_file: 0:32:29.993423\n",
            " 45% 4455/10000 [12:25<15:28,  5.97it/s]saved generated questions. 2000\n",
            " 90% 8981/10000 [25:05<02:59,  5.67it/s]saved generated questions. 4000\n",
            "100% 10000/10000 [27:53<00:00,  6.44it/s]\n",
            "Time of generate 4448 questions: 0:27:53.890536\n",
            "{'Bleu_1': 0.23379676271072083, 'Bleu_2': 0.10682275205021415, 'Bleu_3': 0.05437621740839363, 'Bleu_4': 0.026285221707851122, 'METEOR': 0.18874586156455006, 'ROUGE_L': 0.2829762798661326, 'CIDEr': 0.3459403448452226}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMwBwDCMjJyg",
        "outputId": "bea650ad-dae9-47c8-9572-ee5dc207d377"
      },
      "source": [
        "! chmod 777 ./sampler.py\n",
        "! ./sampler.py"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./sampler.py: /bin/bash^M: bad interpreter: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHUd6NBkosz"
      },
      "source": [
        "! python sampler.py"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}